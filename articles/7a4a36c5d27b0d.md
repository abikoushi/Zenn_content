---
title: "ウィルコクソン順位和検定から得られる信頼区間"
emoji: "🥇"
type: "tech"
topics:
  - "R"
  - 統計学
  - "信頼区間"
  - "仮説検定"
  - "ウィルコクソン検定"
published: true
published_at: "2024-07-07 09:12"
---

## 導入

数理統計の本には良く「信頼区間は検定方式の反転によって得られる」というようなことが書かれている．と，言うときにいま僕が手元で参照しているのは [『現代数理統計学の基礎』（久保川達也, 共立出版）](https://www.kyoritsu-pub.co.jp/book/b10003681.html) だが, これ以外にも表紙のどこかに「数理統計学」と入っているような本には同様のことが書かれていることが多いと思う．

両側検定,

- 帰無仮説: $\theta = \theta_0$（1点）
- 対立仮説: $\theta \neq \theta_0$

の検定統計量 $T(X)$（標本$X$の関数）と受容域 $A(\theta_0)$（帰無仮説のパラメータに依存）から，

$$
P_{\theta_0}(T(X) \in A(\theta_0)) = 1-\alpha
$$

とできるなら，これを $\theta_0$ について解くと，信頼区間

$$
C(X) = \{\theta_0|T(X) \in A(\theta_0)\}
$$

が得られる．

しかし具体例を複数やらないとちょっとわかりにくいかもしれない．そこでここでは2標本のウィルコクソンの順位和検定（単にウィルコクソン検定と呼ばれることもある）を使って信頼区間を求めてみる．


## とりあえず計算してみる

Rでは関数 `wilcox.test` がウィルコクソン検定で，`conf.int=TRUE` とすると信頼区間を出力する．

この信頼区間が帰無仮説を棄却しない $\theta_0$ の範囲と一致することを確かめよう．

```r
library(ggplot2)
set.seed(123)
x <- rweibull(50,1.5) 
y <- rweibull(50,1.5)
U <- outer(x,y,"-") #全部の組み合わせで差を計算

sx <- sort(U[lower.tri(U, diag = TRUE)])
pv_w <- sapply(sx,function(m)wilcox.test(x, y, mu=m)$p.value)
df4p <- data.frame(sx=sx,pv=pv_w)

m <- median(U)
null_wilcox <- wilcox.test(x,y, conf.int = TRUE, conf.level = 0.95)

ggplot(df4p, aes(x=sx))+
  geom_step(aes(y=pv))+
  geom_rug(aes(x=sx), alpha=0.1)+
  annotate(geom="point", x=null_wilcox$estimate,y=1,
           colour="royalblue")+
  annotate(geom = "errorbarh",
           xmin=null_wilcox$conf.int[1],
           xmax=null_wilcox$conf.int[2],
           y=1-0.95,
           height=0.075,
           colour="royalblue")+
  theme_bw(18)+
  labs(y="p-value", x="U")
```

![](https://storage.googleapis.com/zenn-user-upload/e0f7b9062ad8-20240707.png)

図の青いエラーバーが95％信頼区間，曲線が p 値である．

ちなみに信頼区間の幅を0％まで縮めたもの（図中の丸いマーカー）はホッジス・レーマン（Hodges-Lehmann）推定量と呼ばれる．

結局，これが母集団のなにに対応する量を推定しようとしているのかを知るために，改めてウィルコクソン順位和検定を紹介する．


## ウィルコクソン検定の紹介

2群，$X$ グループ: $X_i$ ($i=1, \ldots, m$) と，$Y$ グループ: $Y_j$ ($j=1, \ldots, n$)の比較を考える．

$X_i$ と $Y_j$ をまとめて小さい順に順位をつけると, もし $Y$ グループの方に大きい（小さい）値が多ければ $Y_j$ グループの順位も大きい（小さい）方に偏る．

どちらも同じ分布に従っているとすると $Y_j$ の順位は $\{1, 2, \ldots, n+m-1, n+m\}$ の範囲で一様分布（「同様に確からしい」）になる．

Rによる計算例:

```r
#Rのコード
set.seed(123)
x <- rnorm(2)
y <- rnorm(2)
R <- rank(c(x,y)) #まとめて順位をつける
```

```r
#最初の2列がyグループ
> round(rbind(c(x,y),R),2)
  [,1] [,2]  [,3]  [,4]
  1.56 0.07 -0.56 -0.23
R 4.00 3.00  1.00  2.00
```

Yグループの順位の取りうる値はすべて書き出せる.

(1,2), (1,3), (1,4)
(2,3), (2,4)
(3,4)

これより，Yグループの順位の合計もすべて書き出せる.

3, 4, 5
5, 6
7

この頻度を表にすると,

| 順位の合計 | 3 | 4 | 5 | 6 | 7 |
| ---- | ---- | ---- | ---- | ---- | ---- |
|度数 | 1 | 1 | 2 | 1 | 1 |
|確率 | 1/6 | 1/6 | 2/6 | 1/6 | 1/6 |

となる. 

Rでシミュレーションしてみるとこの数え上げと同じ比の度数になることがわかる:

```r
set.seed(1234)
W <- integer(10000)
for(i in 1:10000){
  x <- rnorm(2)
  y <- rnorm(2)
  R <- rank(c(y,x))
  W[i] <- sum(R[1:2]) #最初のn個がYの順位
}
barplot(table(W))
```

![](https://storage.googleapis.com/zenn-user-upload/a93a904c47f5-20240703.png)


ちなみに, 次のように漸化式を作るともう少し現実的な時間で計算できる:

$$
P(W=k)=p_{m,n}(k)=\frac{n}{m+n} p_{m,n-1}(k-m)+\frac{m}{m+n} p_{m-1,n}(k)
$$

ここでは

$$
W=Xグループの順位の合計 - \sum_{i=1}^m i
$$

と変換して取りうる値の最小値が0になるようにしている．

R の `wilcox.test` が返す値もこの方式である.

この順位の合計を検定統計量にした検定を考えていく．

さて，Xグループの順位の分布は，分布どうしで平均や中央値が同じとしても，分布どうしの形状が違うときは一様にならない．

同じ分布でシミュレーション:

```r
rlis1 <- vector("list", 10000)
for(i in 1:10000){
  x <- rnorm(2)
  y <- rnorm(2)
  R <- rank(c(y,x))
  rlis1[[i]] <- R[1:2] #最初のn個がYの順位
}

barplot(table(unlist(rlis1)))
```

![](https://storage.googleapis.com/zenn-user-upload/df9af4d1ad75-20240703.png)

平均や中央値が同じで分散が違う分布でシミュレーション:

```r
rlis2 <- vector("list", 10000)
for(i in 1:10000){
  x <- rnorm(2,0,1) #分散1
  y <- rnorm(2,0,2) #分散2^2
  R <- rank(c(y,x))
  rlis2[[i]] <- R[1:2] #最初のn個がYの順位
}

barplot(table(unlist(rlis2)))
```

![](https://storage.googleapis.com/zenn-user-upload/752e58891c06-20240707.png)

ここで改めて標準的な両側検定の記法で書くと，$X_1, X_2, \ldots, X_m$, $Y_1, Y_2, \ldots, Y_n$ の2群の標本があり，$X_i$ の分布が $F(x-\mu)$（位置が $\mu$ だけずれている），$Y_j$ の分布が $F(x)$ とするとき，

- 帰無仮説: $\mu = \mu_0$
- 対立仮説: $\mu \neq \mu_0$

を検定するのがウィルコクソン順位和検定である.

ここまでの議論では暗に $\mu_0=0$ の場合を想定していたが，一般の $\mu_0$ に対して検定するためには $X_i-\mu_0$ をXグループとすれば良い.

ところで， 検定統計量を

$$
W = Xグループの順位の合計 - \sum_{i=1}^m i
$$ 

としたが， この $W$ は

$$
U_{ij} =  (X_i - \mu_0) - Y_j
$$

としたときの $U_{ij}>0$ となる $U_{ij}$ の個数と一致する.

![](https://storage.googleapis.com/zenn-user-upload/c8ff0cb0183f-20240703.jpg)
*図は青線がマイナスでオレンジのチェックがプラス. $X$グループの順位が全部小さい方に偏っているときは $U_{ij}>0$ となる $U_{ij}$ の個数は0個, ..., 全部大きい方に偏っているときは $mn$個*

$U_{ij}$ の作り方から，ウィルコクソン検定による信頼区間は「2つの母集団から1つずつ標本を取り出して差を取ったときの中央値」を推定している．

これが知りたいことであった．

〇〇検定と名前のついているものはいっぱいありややこしいが，個人的には「母集団のなにに対応する量を推定しているのか」という視点から理解しようとするといいと思う．

より強い言い方をすると，そこをスキップすると実質的に帰無仮説ロンダリングになってしまうのではないかと思う．


## シミュレーション

差の中央値と中央値の差は一般には一致しないので「2群で中央値が異なる」ことの検定には使えない場合がある．

中央値が（ついでに分散も）同じ分布でシミュレーションしてみよう．

![](/images/7a4a36c5d27b0d/dist_for_sim.png)
*図は中央値と分散が同じだけど形状が違う分布*

```r
library(ggplot2)

#中央値
mu <- qexp(0.5)
print(qnorm(0.5,mu,1))

#分布の形を図で確認
curve(dnorm(x,mu,1),  xlim=c(-2,6), lwd=1.5, ylab="density")
curve(dexp(x), xlim=c(0,6), add=TRUE, lty=2, col="royalblue", lwd=1.5)
legend("topright", c("normal","exp"), lty=1:2, col=c("black", "royalblue"), lwd=1.5)

#差の中央値（数値積分による力技で確認）
conv <- function(x){
#たたみ込み
  integrate(function(y){dnorm(x+y,mu)*dexp(y)},-Inf,0)$value + 
  integrate(function(y){dnorm(x+y,mu)*dexp(y)},0,Inf)$value
}
conv <- Vectorize(conv)
m_root <- uniroot(function(x)integrate(conv,-Inf,x)$value-0.5, c(-1,0))

print(m_root$root)
#-0.1825963

#分散（数値積分による力技で確認）
v_e <- integrate(function(x)x^2*dexp(x), 0,Inf)$value - 
  integrate(function(x)x*dexp(x), 0,Inf)$value^2

v_n <- integrate(function(x)x^2*dnorm(x,mu,1), -Inf,Inf)$value -
  integrate(function(x)x*dnorm(x,mu,1), -Inf,Inf)$value^2

print(v_e)
#1
print(v_n)
#1

#繰り返し計算
n1 <-100
n2 <-100
pv_simfun <- function(n1,n2, mu, m){
  x1 <- rnorm(n1,mu,1)
  x2 <- rexp(n2)
  res_w <- wilcox.test(x1, x2, conf.int=TRUE)
  cp <- res_w$conf.int[1] < m & m < res_w$conf.int[2]
  data.frame(estimate=res_w$estimate,
             pv = res_w$p.value,
             cover = cp)
}

#手元のパソコンだと10秒くらいかかる
system.time({
  res <- lapply(1:10000, 
                function(i){set.seed(i);pv_simfun(25, 25, mu, m_root$root)})
  res <- do.call("rbind",res)
})
#  user  system elapsed 
#10.068   0.051  10.212 

#p値の経験分布
ggplot(res,aes(x=pv))+
  stat_ecdf()+
  geom_abline(slope = 1,intercept = 0, lty=2)+
  theme_bw()+labs(x="nominal", y="actual")
ggsave("wilcox_p.png")

print(round(mean(res$cover),2))
#0.95
```

![](/images/7a4a36c5d27b0d/wilcox_p.png)
*帰無仮説を$\mu_0=0$としたときのp値の分布*

x軸の有意水準で棄却される確率がy軸なので，中央値が同じ分布でも棄却されすぎていることがわかる．

一方で差の中央値の被覆確率については名目上の水準通りに保たれている．

```r
> print(round(mean(res$cover),2))
[1] 0.95
```
このような場面で帰無仮説を $\mu_0=0$ としたウィルコクソン検定を使って「中央値に差がある」という結論を出すのが，上で「帰無仮説ロンダリング」と言ったものの例である．


さてここで，冒頭に述べた仮説検定と信頼区間の関係を思い出してみると，帰無仮説が棄却されることと信頼区間が帰無仮説で指定したパラメータを含まないことは同じであった．

被覆確率を95％以外のいろいろな信頼区間で出してみようとすると大変そうだが，帰無仮説をシミュレーションで設定した真値にしたパラメータのp値の分布をみることと，被覆確率をしらべることが同じだとわかる．

上のコードのシミュレーションでは，

```r
res_w <- wilcox.test(x1, x2, conf.int=TRUE)
```

の1行を

```r
res_w_shift <- wilcox.test(x1, x2, mu=m)
```

に変更すればこれができる．

![](/images/7a4a36c5d27b0d/wilcox_p2.png)
*帰無仮説の $\mu_0$ を差の中央値の真値としたときのp値の分布*

図をみると，この場合はp値がほぼ名目上の水準に保たれている．

シミュレーションで使用したコードの全体像はこちら：

https://github.com/abikoushi/Zenn_content/blob/main/R/7a4a36c5d27b0d.R

## 追記

この文書はもともと「ウィルコクソン検定から得られる信頼区間」というタイトルで公開していましたが，ウィルコクソン符号付き順位和検定との混同を避けるために改題しました．同じ理由で本文中の「ウィルコクソン検定」も「ウィルコクソン順位和検定」に置換した箇所があります．

さらに，(scenario 2)のほうのシミュレーションはあとから追加しました．

これらの変更履歴は連携している GitHub のリポジトリからも確認できます．

